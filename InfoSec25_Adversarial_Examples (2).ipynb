{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xO-XBsYMOiR"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BHkSCcGWfkls",
        "outputId": "7a07d38b-89a1-47c0-d66f-0ece1d9cef1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving results to 'results'. If you're using Google Colab, this folder will be deleted when you disconnect!\n"
          ]
        }
      ],
      "source": [
        "use_gdrive = False # @param {type:\"boolean\"}\n",
        "\n",
        "RESULTS_PATH = \"results\"\n",
        "\n",
        "if use_gdrive:\n",
        "  try:\n",
        "    # mount your google drive to get permanent storage for your results\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    RESULTS_PATH = \"/content/drive/MyDrive/infoseclab25/results\"\n",
        "  except ModuleNotFoundError:\n",
        "    print(\"failed to mount gdrive\")\n",
        "else:\n",
        "  print(f\"saving results to '{RESULTS_PATH}'. If you're using Google Colab, this folder will be deleted when you disconnect!\")\n",
        "\n",
        "!mkdir -p {RESULTS_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aCjvBq6rL0n1",
        "outputId": "28b5e9d9-2310-44b2-efcd-fc7735e584d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/infoseclab_25\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "# Lab files\n",
        "![ ! -d 'infoseclab_25' ] && git clone https://github.com/ethz-spylab/infoseclab_25.git\n",
        "%cd infoseclab_25\n",
        "#!git pull https://github.com/ethz-spylab/infoseclab_25.git\n",
        "%cd ..\n",
        "if \"infoseclab_25\" not in sys.path:\n",
        "  sys.path.append(\"infoseclab_25\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXC5q0RvNhhh"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Uwi_QoU9Nguf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import infoseclab\n",
        "from infoseclab import defenses, CIFAR10, EPSILON, utils, evaluation\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHhM612yjnBu"
      },
      "source": [
        "# 0.&nbsp; A quick primer on constrained optimization in PyTorch\n",
        "\n",
        "To get a feel for how to optimize functions in PyTorch over a domain, below we solve a simple 1-dimensional function mimization problem.\n",
        "\n",
        "We want to find the minimum of $f(x)$ under the constraint $x \\in [-1, 1]$.\n",
        "\n",
        "(the actual minimimum is at $x=\\sqrt{2/3} \\approx 0.8165$ and has value $f(x) \\approx -6.089$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tIsix6s_jmbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9a0c85-7be7-403d-d86a-be3daea22155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: f(0.00) = -5.000\n",
            "step 1: f(0.05) = -5.100\n",
            "step 2: f(0.10) = -5.199\n",
            "step 3: f(0.15) = -5.297\n",
            "step 4: f(0.20) = -5.392\n",
            "step 5: f(0.25) = -5.484\n",
            "step 6: f(0.30) = -5.573\n",
            "step 7: f(0.35) = -5.657\n",
            "step 8: f(0.40) = -5.736\n",
            "step 9: f(0.45) = -5.809\n",
            "step 10: f(0.50) = -5.875\n",
            "step 11: f(0.55) = -5.934\n",
            "step 12: f(0.60) = -5.984\n",
            "step 13: f(0.65) = -6.025\n",
            "step 14: f(0.70) = -6.057\n",
            "step 15: f(0.75) = -6.078\n",
            "step 16: f(0.80) = -6.088\n",
            "step 17: f(0.85) = -6.086\n",
            "step 18: f(0.80) = -6.088\n",
            "step 19: f(0.85) = -6.086\n"
          ]
        }
      ],
      "source": [
        "# the function we want to minimize\n",
        "def f(x):\n",
        "  return x**3 - 2*x - 5\n",
        "\n",
        "# our starting point\n",
        "x = torch.zeros(1).to(device)\n",
        "\n",
        "for i in range(20):\n",
        "  x.requires_grad_(True)  # we want to take gradients with respect to x\n",
        "\n",
        "  objective = f(x)            # compute the current objective\n",
        "  objective.backward()        # take the gradient of the objective with respect to all inputs\n",
        "  grad = x.grad.detach().clone()     # get the value of the gradient with respect to x\n",
        "\n",
        "  print(f\"step {i}: f({x.item():.2f}) = {objective.item():.3f}\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    x = x - 0.05 * torch.sign(grad)  # take a gradient update step to minimize the objective\n",
        "    x = torch.clamp(x, -1, 1)        # ensure we stay in the allowed range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTX2x8NYS9LN"
      },
      "source": [
        "# 0.1&nbsp; Foreword\n",
        "Below you will find several exercises that will introduce you into the field of adversarial attacks and help you get some hands on experience. We prepared a code skeleton in each cell that you are STRONGLY encouraged to use so that you can focus on the core of each exercise. Your mission, should you chose to accept it - is to create a series of adversarial attacks that will overpower example defenses one at a time. You will be asked to save those attacks and submit them as your assignment - the last cells in this notebook will guide you through the process, make sure to follow them closely as otherwise we will not grade your exercies.\n",
        "\n",
        "Lastly, a few tips:\n",
        "* In each exercise it will be specified whether the attack is supposed to be targeted or not, so make sure you take that into account when devising your attacks.\n",
        "* No attack requires more than 50 gradient steps (per batch), so if you are running 1000 gradient steps to no avail, there is either a bug in your code or you need to take a different approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV7wnlsjNyYb"
      },
      "source": [
        "# 1.&nbsp;Targeted PGD attack on undefended ResNet-18 [10 points]\n",
        "\n",
        "We will first run a simple *targeted* PGD attack, where the goal is to get the model to misclassify an input `(x, y)` into a specific incorrect class `y'`.\n",
        "\n",
        "You can design your attack however you'd like, but we recommend first\n",
        "implementing a `project` method that projects an adversarial example\n",
        "onto the l_inf ball centered at the original sample. It is customary to\n",
        "also ensure that the projected sample is in the valid range for an image (i.e.,\n",
        "all pixel values in [0, 255]).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bEsJ9nz_N11y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f938b14-9b53-455b-bcfe-6ee0eb437035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:05<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD ===\n",
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 100.0% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "class PGD(object):\n",
        "    \"\"\"\n",
        "    A targeted PGD attack in l_inf norm.\n",
        "    \"\"\"\n",
        "\n",
        "    dsteps = 30\n",
        "    dstep_size = 2.5*EPSILON/20\n",
        "    def __init__(self, epsilon, clf, steps=None, step_size=None):\n",
        "        \"\"\"\n",
        "        :param epsilon: the maximum perturbation allowed\n",
        "        :param clf: the classifier to attack\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.clf = clf\n",
        "        #anfang steps udn step_size values\n",
        "        self.steps = steps if steps is not None else PGD.dsteps\n",
        "        self.step_size = step_size if step_size is not None else PGD.dstep_size\n",
        "\n",
        "    def project(self, x_adv, x_orig):\n",
        "        \"\"\"\n",
        "        Project x_adv onto the epsilon ball around x_orig.\n",
        "        :param x_adv: the adversarial images\n",
        "        :param x_orig: the clean images\n",
        "        :return: the adversarial images projected onto the epsilon ball, in the range [0, 255]\n",
        "        \"\"\"\n",
        "        return torch.round(torch.clamp(torch.clamp(x_adv, x_orig - self.epsilon, x_orig + self.epsilon), 0, 255))\n",
        "\n",
        "    def attack_batch(self, x, y_targets):\n",
        "        \"\"\"\n",
        "        Attack a batch of images with PGD.\n",
        "        :param x: the batch of images (torch tensors) to attack of size (batch_size, 3, 32, 32)\n",
        "        :param y_targets: the target labels of size (batch_size,)\n",
        "        :return: the adversarial images of size (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x_adv = x.to(self.clf.device)\n",
        "        x_orig = x.to(self.clf.device)\n",
        "        y_targets = y_targets.to(self.clf.device)\n",
        "\n",
        "        for i in range(self.steps):\n",
        "            x_adv.requires_grad_(True)\n",
        "            logits = self.clf.get_logits(x_adv)\n",
        "            loss = torch.nn.functional.cross_entropy(logits, y_targets)\n",
        "            loss.backward()\n",
        "            grad = x_adv.grad.sign()\n",
        "            x_adv = x_adv - self.step_size * grad\n",
        "            x_adv = self.project(x_adv, x_orig)\n",
        "            x_adv = x_adv.detach()\n",
        "        return x_adv\n",
        "\n",
        "    def attack_all(self, images, labels, batch_size=20):\n",
        "        \"\"\"\n",
        "        A utility to attack all images in the dataset by batching.\n",
        "        :param images: the images to attack, of size (N, 3, 32, 32) in the range [0, 255]\n",
        "        :param labels: the target labels\n",
        "        :param batch_size: the batch size to use\n",
        "        :return: the adversarial images\n",
        "        \"\"\"\n",
        "        return utils.batched_func(self.attack_batch, inputs=(images, labels),\n",
        "                                  batch_size=batch_size,\n",
        "                                  device=self.clf.device)\n",
        "\n",
        "# load defense\n",
        "#xsmall = CIFAR10.clean_images[:4]\n",
        "#ytsmall = CIFAR10.targets[:4]\n",
        "#device = \"cpu\"\n",
        "resnet = defenses.ResNet(device)\n",
        "\n",
        "pgd = PGD(epsilon=EPSILON, clf=resnet)\n",
        "#xsmall = pgd.attack_batch(xsmall, ytsmall)\n",
        "x_adv = pgd.attack_all(CIFAR10.clean_images, CIFAR10.targets, batch_size=64)\n",
        "utils.save_images(os.path.join(RESULTS_PATH, \"x_adv_targeted.pt\"), x_adv)\n",
        "evaluation.eval_targeted_pgd(os.path.join(RESULTS_PATH, \"x_adv_targeted.pt\"), device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "V0J7Anb0ani3",
        "outputId": "ce1cde60-204b-403f-c5b6-e12f3959872b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# you can visualize your attack samples as follows if this helps\n",
        "idx = 2\n",
        "input = torch.stack([x_adv[idx], CIFAR10.clean_images[idx]]).to(device)\n",
        "logits = resnet.get_logits(input)\n",
        "utils.display(x_adv[idx], image_orig=CIFAR10.clean_images[idx], logits=logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9myeLu4a5xB"
      },
      "source": [
        "**Text fett markieren**# 2.&nbsp;Evading Detection [25 points]\n",
        "\n",
        "It turns out that \"naive\" adversarial examples are very easy to *detect*.\n",
        "So one could build a defense that aims to detect when an input has been perturbed, to reject it and raise an alarm.\n",
        "\n",
        "Unfortunately, as we'll see such defenses are hard to make robust against an *adaptive* attacker that also optimizes over the detector.\n",
        "\n",
        "You will now implement attacks against two detector defenses:\n",
        "\n",
        "<ul>\n",
        "  <li> 2.1. A detector using a standard neural network. </li>\n",
        "  <li> 2.2. A Random Forest detector </li>\n",
        "<ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wEsVJ2M3a5Ku",
        "outputId": "e999b268-c189-4d22-a380-7aa68a2bc0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD with Neural Network Detector ===\n",
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 100.0% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32m\tclean examples detected: 3.5% (target: ≤5.0%)\u001b[0m\n",
            "\u001b[31m\tadv examples detected: 93.5% (target: ≤1.0%)\u001b[0m\n",
            "\u001b[31mNOT THERE YET!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "device = \"cpu\"\n",
        "# Your previous attack is likely easily detected\n",
        "evaluation.eval_detector_attack(os.path.join(RESULTS_PATH, \"x_adv_targeted.pt\"), device=device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpHESdu-h6bO"
      },
      "source": [
        "## 2.1&nbsp;Evading A Neural Network Detector [10 points]\n",
        "\n",
        "We will first do a targeted attack against the `ResNetDetector` defense.\n",
        "This defense takes the standard `ResNet` classifier from before, and adds an additional detector network.\n",
        "\n",
        "The defense can be used for classification, in which case it outputs an array of scores for each of the 10 classes, for each input:\n",
        "\n",
        "```\n",
        "resnet_det = ResNetDetector(device)\n",
        "resnet_det.get_logits(x) -> [N, 10]\n",
        "```\n",
        "\n",
        "To obtain a detector, we trained a *binary* classifier that takes in an input and outputs binary logits for the task of distinguishing clean images (class 0) from adversarially perturbed ones (class 1):\n",
        "\n",
        "```\n",
        "resnet_det = ResNetDetector(device)\n",
        "resnet_det.get_detection_logits(x) -> [N, 2]\n",
        "```\n",
        "\n",
        "*(the classifier and detector actually share most of their implementation.\n",
        "The original ResNet classifier is of the form `g(f(x))` where `f` is a <u>feature extractor</u> that maps inputs to feature vectors, and `g` is a <u>linear layer</u> that maps a feature vector to a vector of 10 class scores.\n",
        "The detector takes as input the same feature vector `f(x)`, and applies a different linear layer `g_det` that maps the features to a vector of 2 class scores.\n",
        "See `infoseclab.defenses.defense_detector.ResNetDetector` for details).*\n",
        "\n",
        "Note: You are allowed to use the `ResNetDetector` module in your attack, but you are not allowed to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "W7V6HnP5b4LR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd04fbab-b820-4799-e386-570c2f6f8375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:10<00:00,  2.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD with Neural Network Detector ===\n",
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 100.0% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32m\tclean examples detected: 3.5% (target: ≤5.0%)\u001b[0m\n",
            "\u001b[32m\tadv examples detected: 0.0% (target: ≤1.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "class PGD_Det(PGD):\n",
        "    \"\"\"\n",
        "    A targeted PGD attack that also tries to evade detection.\n",
        "    \"\"\"\n",
        "    # 0.7, oder 0.5 oder\n",
        "    dalpha = 0.5\n",
        "    def __init__(self, epsilon, clf, steps=None, step_size=None, alpha=None):\n",
        "        \"\"\"\n",
        "        :param epsilon: the maximum perturbation allowed\n",
        "        :param clf: the classifier to attack\n",
        "        \"\"\"\n",
        "        super().__init__(epsilon, clf, steps, step_size)\n",
        "        self.alpha = PGD_Det.dalpha if alpha is None else alpha\n",
        "\n",
        "    def attack_batch(self, x, y_targets):\n",
        "        \"\"\"\n",
        "        Attack a batch of images with targeted PGD while also evading detection.\n",
        "        :param x: the batch of images (torch tensors) to attack of size (batch_size, 3, 32, 32)\n",
        "        :param y_targets: the target labels of size (batch_size,)\n",
        "        :return: the adversarial images of size (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x_adv = x.to(self.clf.device)\n",
        "        x_orig = x.to(self.clf.device)\n",
        "        y_targets = y_targets.to(self.clf.device)\n",
        "        clabels = torch.zeros(x_adv.size(0), dtype=torch.long, device=self.clf.device)\n",
        "\n",
        "      #verbessere\n",
        "        for _ in range(self.steps):\n",
        "            x_adv.requires_grad_(True)\n",
        "            logits = self.clf.get_logits(x_adv)\n",
        "            target_loss = torch.nn.functional.cross_entropy(logits, y_targets)\n",
        "\n",
        "            dlogits = self.clf.get_detection_logits(x_adv)\n",
        "            dloss = torch.nn.functional.cross_entropy(dlogits, clabels)\n",
        "            loss = target_loss + self.alpha * dloss\n",
        "            loss.backward()\n",
        "\n",
        "            grad = x_adv.grad.sign()\n",
        "            x_adv = x_adv - self.step_size * grad\n",
        "            x_adv = self.project(x_adv, x_orig)\n",
        "            x_adv = x_adv.detach()\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "device = \"cuda\"\n",
        "defense_det = defenses.ResNetDetector(device)\n",
        "pgd_det = PGD_Det(epsilon=EPSILON, clf=defense_det, alpha=0.5)\n",
        "x_adv_det = pgd_det.attack_all(CIFAR10.clean_images, CIFAR10.targets, batch_size=64)\n",
        "\n",
        "utils.save_images(os.path.join(RESULTS_PATH, \"x_adv_detect.pt\"), x_adv_det)\n",
        "evaluation.eval_detector_attack(os.path.join(RESULTS_PATH, \"x_adv_detect.pt\"), device=device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMlKoqzTcLNV"
      },
      "source": [
        "## 2.2&nbsp;Evading a Random Forest Detector [15 points]\n",
        "\n",
        "You will now try to attack a second detector defense.\n",
        "As with the previous defense, we first classify the input in a standard way using the ResNet18 model.\n",
        "\n",
        "But this time, the detector is an opaque \"Random Forest\" model that takes as\n",
        "input the features from the resnet model and outputs a decision.\n",
        "This is a discrete model (a Random Forest is a collection of decision trees) that cannot be easily differentiated. So you'll need\n",
        "a new strategy!\n",
        "\n",
        "**For this defense, your attack can be untargeted. That is, it suffices that the adversarial examples are classified into <i>any</i> incorrect class, as long as the detector doesn't flag the sample.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2FBBIk2YcAdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb310b8-45ea-4190-d922-f89d76029009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "100%|██████████| 4/4 [00:05<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating untargeted PGD with Random Forest Detector ===\n",
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 5.0%)\u001b[0m\n",
            "\u001b[32m\tclean examples detected: 0.0% (target: ≤5.0%)\u001b[0m\n",
            "\u001b[32m\tadv examples detected: 0.0% (target: ≤1.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "class PGD_Det_RF(PGD):\n",
        "    \"\"\"\n",
        "    A PGD attack that also tries to evade detection with a random forest.\n",
        "    \"\"\"\n",
        "    dalpha= 0.7\n",
        "    def __init__(self, epsilon, clf, steps=None, step_size=None, alpha=None):\n",
        "        \"\"\"\n",
        "        :param epsilon: the maximum perturbation allowed\n",
        "        :param clf: the classifier to attack\n",
        "        \"\"\"\n",
        "        super().__init__(epsilon, clf, steps, step_size)\n",
        "        self.alpha = PGD_Det_RF.dalpha if alpha is None else alpha\n",
        "\n",
        "    def attack_batch(self, x, y):\n",
        "        \"\"\"\n",
        "        Attack a batch of images with PGD while also evading detection.\n",
        "        :param x: the batch of images (torch tensors) to attack of size (batch_size, 3, 32, 32)\n",
        "        :param y: the labels of size (batch_size,)\n",
        "        :return: the adversarial images of size (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x_adv = x.to(self.clf.device)\n",
        "        x_orig = x.to(self.clf.device)\n",
        "        y = y.to(self.clf.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            lclean = self.clf.get_logits(x_orig)\n",
        "            pclean = torch.nn.functional.softmax(lclean, dim=1)\n",
        "\n",
        "        for _ in range(self.steps):\n",
        "            x_adv.requires_grad_(True)\n",
        "            logitsadv = self.clf.get_logits(x_adv)\n",
        "            clogits = logitsadv.gather(1, y.unsqueeze(1)).squeeze()\n",
        "            wlogits = logitsadv.clone()\n",
        "            wlogits.scatter_(1, y.unsqueeze(1), -1e10)\n",
        "            max_wlogits = wlogits.max(dim=1)[0]\n",
        "\n",
        "            # try out difrent numbers\n",
        "            lossm = torch.nn.functional.relu(clogits - max_wlogits + 6.0).mean()\n",
        "            logpadv = torch.nn.functional.log_softmax(logitsadv, dim=1)\n",
        "            loss_kl = torch.nn.functional.kl_div(\n",
        "                logpadv, pclean, reduction='batchmean', log_target=False)\n",
        "\n",
        "            loss = lossm + self.alpha * loss_kl\n",
        "            loss.backward()\n",
        "            x_adv = self.project(x_adv - self.step_size * x_adv.grad.sign(), x_orig).detach()\n",
        "\n",
        "        return x_adv\n",
        "device = \"cuda\"\n",
        "defense_det_rf = defenses.RFDetector(device)\n",
        "pgd_det_rf = PGD_Det_RF(epsilon=EPSILON, clf=defense_det_rf, step_size=PGD.dstep_size*1.1, alpha=1.00)\n",
        "x_adv_det_rf = pgd_det_rf.attack_all(CIFAR10.clean_images, CIFAR10.labels, batch_size=64)\n",
        "\n",
        "utils.save_images(os.path.join(RESULTS_PATH, \"x_adv_detect_rf.pt\"), x_adv_det_rf)\n",
        "evaluation.eval_rf_detector_attack(os.path.join(RESULTS_PATH, \"x_adv_detect_rf.pt\"), device=device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdorMrPt-Vpf"
      },
      "source": [
        "# 3.&nbsp; Preprocessing Defenses [35 points]\n",
        "\n",
        "We are now going to look at two defenses against adversarial examples that aim to resist noise by *pre-processing* the input before classifying it.\n",
        "\n",
        "<ul>\n",
        "  <li> 3.1. Blurring </li>\n",
        "  <li> 3.2. Random cropping and noising </li>\n",
        "  <li> 3.3. Discretized inputs </li>\n",
        "<ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y_q-ox3c_qb"
      },
      "source": [
        "## 3.1&nbsp; Blurring [10 points]\n",
        "\n",
        "A natural defense idea is to try and remove the noise from adversarial images. A simple way of trying to do that is to add a blurring filter.\n",
        "\n",
        "The `ResNetBlur` defense implements this. Your goal is to create a targeted PGD attack that will defeat Blurring.\n",
        "You **don't** need to ensure that the attack stays undetected.\n",
        "\n",
        "The challenge you'll encounter is that the Blurring filter we use is not automatically differentiable. You'll likely need to find a way around that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GlbbYrsIgnsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93874210-910b-4011-ac8a-077a9055d63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:15<00:00,  3.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD on blurred defense ===\n",
            "\u001b[32m\tclean accuracy: 95.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.5% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 99.5% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from infoseclab.defenses.defense_blur import blur_images\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PGD_Blur(PGD):\n",
        "    \"\"\"\n",
        "    A targeted PGD attack that tries to resist Blurring.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon, clf, steps=None, step_size=None):\n",
        "        \"\"\"\n",
        "        :param epsilon: the maximum perturbation allowed\n",
        "        :param clf: the classifier to attack\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(epsilon, clf, steps, step_size)\n",
        "\n",
        "    def attack_batch(self, x, y_targets):\n",
        "        \"\"\"\n",
        "        Attack a batch of images with targeted PGD while also resisting JPEG compression.\n",
        "        :param x: the batch of images (torch tensors) to attack of size (batch_size, 3, 32, 32)\n",
        "        :param y_targets: the target labels of size (batch_size,)\n",
        "        :return: the adversarial images of size (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x_adv = x.to(self.clf.device)\n",
        "        x_orig = x.to(self.clf.device)\n",
        "        y_targets = y_targets.to(self.clf.device)\n",
        "\n",
        "        for _ in range(self.steps):\n",
        "           # mach, verbesser bis suntig, suscht überspring\n",
        "            x_adv.requires_grad_(True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                x_blur = blur_images(x_adv)\n",
        "\n",
        "            x_blur = x_blur.detach()\n",
        "            x_blur.requires_grad_(True)\n",
        "\n",
        "            logits = self.clf.model(self.clf.normalize(x_blur / 255.0))\n",
        "            loss = F.cross_entropy(logits, y_targets)\n",
        "            loss.backward()\n",
        "            grad = x_blur.grad.detach()\n",
        "            x_adv = self.project(x_adv - self.step_size * grad.sign(), x_orig).detach()\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "defense_blur = defenses.ResNetBlur(device)\n",
        "pgd_blur = PGD_Blur(epsilon=EPSILON, clf=defense_blur, steps=60, step_size=PGD.dstep_size)\n",
        "x_adv_blur = pgd_blur.attack_all(CIFAR10.clean_images, CIFAR10.targets, batch_size=64)\n",
        "\n",
        "utils.save_images(os.path.join(RESULTS_PATH, \"x_adv_blur.pt\"), x_adv_blur)\n",
        "evaluation.eval_blur_attack(os.path.join(RESULTS_PATH, \"x_adv_blur.pt\"), device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag6TwSfy_Y8Z"
      },
      "source": [
        "## 3.2&nbsp; Randomized cropping and noising [10 points]\n",
        "\n",
        "Another natural defense idea is to try and *randomize* the model's behavior to make it harder to create adversarial examples.\n",
        "\n",
        "The ResNetRandom defense implements this, by randomly cropping and noising input images before classifying them.\n",
        "\n",
        "Your goal is to create a targeted PGD attack that will defeat randomized pre-processing.\n",
        "In this part, you **don't** need to ensure that the attack stays undetected.\n",
        "\n",
        "**Note that since this defense is randomized, the evaluation results might vary slightly from one run to the next. To make sure that your attack passes our final evaluation, try to create an attack that has a few % of slack compared to the evaluation targets (e.g., if we target an adversarial accuracy below 5%, aim to ensure that your attack reaches ~3% or lower)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sH64CeqCAzFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb404e74-43ef-43f8-f417-04c31c7feb93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:39<00:00,  9.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD on randomized defense ===\n",
            "\u001b[32m\tclean accuracy: 92.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 1.0% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 99.0% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "class PGD_Random(PGD):\n",
        "    \"\"\"\n",
        "    A PGD attack that also tries to resist random preprocessing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon, clf, steps=None, step_size=None, eot_samples=4):\n",
        "        super().__init__(epsilon, clf, steps, step_size)\n",
        "        self.eot_samples = eot_samples\n",
        "\n",
        "    def attack_batch(self, x, y_targets):\n",
        "        \"\"\"\n",
        "        Attack a batch of images with targeted PGD while also evading random preprocessing.\n",
        "        :param x: the batch of images (torch tensors) to attack of size (batch_size, 3, 32, 32)\n",
        "        :param y_targets: the target labels of size (batch_size,)\n",
        "        :return: the adversarial images of size (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x_adv = x.to(self.clf.device)\n",
        "        x_orig = x.to(self.clf.device)\n",
        "        y_targets = y_targets.to(self.clf.device)\n",
        "\n",
        "        for _ in range(self.steps):\n",
        "            x_adv.requires_grad_(True)\n",
        "            gradac = torch.zeros_like(x_adv)\n",
        "            for _ in range(self.eot_samples):\n",
        "                advtrans = self.clf.random_preproc(x_adv)\n",
        "                logits = self.clf.model(self.clf.normalize(advtrans / 255.0))\n",
        "                loss = F.cross_entropy(logits, y_targets)\n",
        "                loss.backward()\n",
        "                gradac += x_adv.grad.detach()\n",
        "                x_adv.grad.zero_()\n",
        "            gradac /= self.eot_samples\n",
        "            x_adv = self.project(x_adv - self.step_size * gradac.sign(), x_orig).detach()\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "defense_random = defenses.ResNetRandom(device)\n",
        "pgd_random = PGD_Random(epsilon=EPSILON, clf=defense_random, steps=40,step_size=PGD.dstep_size*1.1, eot_samples=6)\n",
        "x_adv_random = pgd_random.attack_all(CIFAR10.clean_images, CIFAR10.targets, batch_size=64)\n",
        "\n",
        "utils.save_images(os.path.join(RESULTS_PATH, \"x_adv_random.pt\"), x_adv_random)\n",
        "evaluation.eval_random_attack(os.path.join(RESULTS_PATH, \"x_adv_random.pt\"), device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IqqopaZfTdS"
      },
      "source": [
        "## 3.3&nbsp; Discretized inputs [15 points]\n",
        "\n",
        "This final defense does something a bit crazy to make it hard for you to compute gradients (a lot of proposed defenses against adversarial examples used to do this, but none of them work...)\n",
        "\n",
        "This defense discretizes the model's inputs as follows: each pixel (in the range [0, 1]) is mapped to an array of 200 binary \"buckets\", where the i-th bucket is set if the input pixel is greater than i/200. So for example we encode `0.00` as `[0 0 0 0 0 ... 0]`, `0.01` as `[1 1 0 0 ... 0]` and `1.00` as `[1 1 1 1 1 ... 1]`.\n",
        "\n",
        "See the `ResNetDiscrete` defense for the implementation of this encoding.\n",
        "\n",
        "The encoded inputs are then fed into a ResNet-style model (which was modified to take in inputs with `3*200` pixel channels instead of `3`).\n",
        "\n",
        "Your goal is to create targeted adversarial examples that break this defense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-CHBUCELfS16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fe6a2a-361a-422b-8a2f-f8826915d6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:23<00:00,  5.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD on discretized defense ===\n",
            "\u001b[32m\tclean accuracy: 96.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.5% (target: ≤ 12.5%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 98.5% (target: ≥85.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from infoseclab.defenses.defense_discrete import N_BINS\n",
        "\n",
        "class PGD_Discrete(PGD):\n",
        "    \"\"\"\n",
        "    A PGD attack that also tries to resist input discretization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon, clf, steps=None, step_size=None):\n",
        "        super().__init__(epsilon, clf, steps, step_size)\n",
        "\n",
        "    def attack_batch(self, x, y_targets):\n",
        "        \"\"\"\n",
        "        Attack a batch of images with targeted PGD while also evading random preprocessing.\n",
        "        :param x: the batch of images (torch tensors) to attack of size (batch_size, 3, 32, 32)\n",
        "        :param y_targets: the target labels of size (batch_size,)\n",
        "        :return: the adversarial images of size (batch_size, 3, 32, 32)\n",
        "        \"\"\"\n",
        "        x_adv = x.to(self.clf.device)\n",
        "        x_orig = x.to(self.clf.device)\n",
        "        y_targets = y_targets.to(self.clf.device)\n",
        "\n",
        "        for _ in range(self.steps):\n",
        "            x_adv.requires_grad_(True)\n",
        "            x_norm = (x_adv / 255.0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                z = self.clf.encode(x_norm)\n",
        "\n",
        "            z = z.detach()\n",
        "            z.requires_grad_(True)\n",
        "            logits = self.clf.model(z)\n",
        "            loss = F.cross_entropy(logits, y_targets)\n",
        "            loss.backward()\n",
        "\n",
        "            gradz = z.grad.detach()\n",
        "            b, cbins, h, w = gradz.shape\n",
        "            nbins = cbins // 3\n",
        "            gradz_view = gradz.view(b, 3, nbins, h, w)\n",
        "            gradx_norm = gradz_view.sum(dim=2)\n",
        "            gradx = gradx_norm / 255.0\n",
        "\n",
        "            x_adv = self.project(x_adv - self.step_size * gradx.sign(), x_orig).detach()\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "defense = defenses.ResNetDiscrete(device)\n",
        "pgd_discrete = PGD_Discrete(epsilon=EPSILON, clf=defense, steps=60, step_size=PGD.dstep_size*1.1)\n",
        "x_adv_discrete = pgd_discrete.attack_all(CIFAR10.clean_images, CIFAR10.targets, batch_size=64)\n",
        "utils.save_images(os.path.join(RESULTS_PATH, \"x_adv_discrete.pt\"), x_adv_discrete)\n",
        "evaluation.eval_discrete_attack(os.path.join(RESULTS_PATH, \"x_adv_discrete.pt\"), device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Cmw-Qj8mLe"
      },
      "source": [
        "# Create submission file (**upload `results.zip` to moodle**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "197yEKu1J_-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac6ab36-9601-413c-e395-dc70045cc27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: x_adv_targeted.pt (deflated 67%)\n",
            "  adding: x_adv_discrete.pt (deflated 67%)\n",
            "  adding: x_adv_detect.pt (deflated 67%)\n",
            "  adding: x_adv_detect_rf.pt (deflated 67%)\n",
            "  adding: x_adv_random.pt (deflated 67%)\n",
            "  adding: x_adv_blur.pt (deflated 67%)\n"
          ]
        }
      ],
      "source": [
        "!zip -j -r \"{RESULTS_PATH}/results1.zip\" {RESULTS_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yW3j3t9y9ZVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52749f6-c57f-4ea6-929b-3ab1b771090c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluating targeted PGD ===\n",
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 100.0% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n",
            "=== Evaluating targeted PGD with Neural Network Detector ===\n",
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 100.0% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32m\tclean examples detected: 3.5% (target: ≤5.0%)\u001b[0m\n",
            "\u001b[32m\tadv examples detected: 0.0% (target: ≤1.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n",
            "=== Evaluating untargeted PGD with Random Forest Detector ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.7.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\tclean accuracy: 100.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.0% (target: ≤ 5.0%)\u001b[0m\n",
            "\u001b[32m\tclean examples detected: 0.0% (target: ≤5.0%)\u001b[0m\n",
            "\u001b[32m\tadv examples detected: 0.0% (target: ≤1.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n",
            "=== Evaluating targeted PGD on blurred defense ===\n",
            "\u001b[32m\tclean accuracy: 95.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.5% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 99.5% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n",
            "=== Evaluating targeted PGD on randomized defense ===\n",
            "\u001b[32m\tclean accuracy: 91.5%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.5% (target: ≤ 2.0%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 99.5% (target: ≥98.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n",
            "=== Evaluating targeted PGD on discretized defense ===\n",
            "\u001b[32m\tclean accuracy: 96.0%\u001b[0m\n",
            "\u001b[32m\tadv accuracy: 0.5% (target: ≤ 12.5%)\u001b[0m\n",
            "\u001b[32m\tadv target accuracy: 98.5% (target: ≥85.0%)\u001b[0m\n",
            "\u001b[32mSUCCESS\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from infoseclab.evaluation import eval_targeted_pgd, eval_detector_attack, eval_rf_detector_attack, eval_blur_attack, eval_random_attack, eval_discrete_attack\n",
        "with ZipFile(f\"{RESULTS_PATH}/results1.zip\", 'r') as zip:\n",
        "    _ = eval_targeted_pgd(path=zip.open(\"x_adv_targeted.pt\"), device=device)\n",
        "    _ = eval_detector_attack(path=zip.open(\"x_adv_detect.pt\"), device=device)\n",
        "    _ = eval_rf_detector_attack(path=zip.open(\"x_adv_detect_rf.pt\"), device=device)\n",
        "    _ = eval_blur_attack(path=zip.open(\"x_adv_blur.pt\"), device=device)\n",
        "    _ = eval_random_attack(path=zip.open(\"x_adv_random.pt\"), device=device)\n",
        "    _ = eval_discrete_attack(path=zip.open(\"x_adv_discrete.pt\"), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from infoseclab.submission import validate_zip1\n",
        "assert validate_zip1(f\"{RESULTS_PATH}/results1.zip\")"
      ],
      "metadata": {
        "id": "oq9KcB9CJobo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f900979-6b76-4413-dd73-4673491107eb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file is valid\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KHhM612yjnBu"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}